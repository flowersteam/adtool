{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.34.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/flowers-user/anaconda3/envs/adtool/lib/python3.11/site-packages (from openai) (4.3.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/flowers-user/anaconda3/envs/adtool/lib/python3.11/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/flowers-user/anaconda3/envs/adtool/lib/python3.11/site-packages (from openai) (2.7.1)\n",
      "Requirement already satisfied: sniffio in /home/flowers-user/anaconda3/envs/adtool/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/flowers-user/anaconda3/envs/adtool/lib/python3.11/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/flowers-user/anaconda3/envs/adtool/lib/python3.11/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/flowers-user/anaconda3/envs/adtool/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /home/flowers-user/anaconda3/envs/adtool/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/flowers-user/anaconda3/envs/adtool/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/flowers-user/anaconda3/envs/adtool/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/flowers-user/anaconda3/envs/adtool/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /home/flowers-user/anaconda3/envs/adtool/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
      "Downloading openai-1.34.0-py3-none-any.whl (325 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: distro, openai\n",
      "Successfully installed distro-1.9.0 openai-1.34.0\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image, Audio\n",
    "\n",
    "import cv2\n",
    "import base64\n",
    "import time\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import requests\n",
    "\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 frames read.\n"
     ]
    }
   ],
   "source": [
    "video = cv2.VideoCapture(\"/home/flowers-user/Downloads/discoveries/2024-06-06T15:13_exp_0_idx_276_seed_42/fecb27c5e2f6049b97554b79e1dfcd16f4c0bd3b.mp4\")\n",
    "\n",
    "base64Frames = []\n",
    "while video.isOpened():\n",
    "    success, frame = video.read()\n",
    "    if not success:\n",
    "        break\n",
    "    _, buffer = cv2.imencode(\".jpg\", frame)\n",
    "    base64Frames.append(base64.b64encode(buffer).decode(\"utf-8\"))\n",
    "\n",
    "video.release()\n",
    "print(len(base64Frames), \"frames read.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(base64Frames[0::500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_FRAMES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p= \"\"\"Here's a series of images spaced one second apart.\n",
    "With the eye of an expert biologist, mathematician, computer scientist, physicist, chemist, naturalist, historical and contemporary art, describe in the same time precisely, qualitatively and quantitatively, at high and low level, the following process and intricate patterns.\n",
    "Don't just say 'complex' or 'detailed', be more precise by using a tailored vocabulary to describe spatial and temporal patterns (even from one frame to the other), and making analogies with real-world objects or phenomena.\n",
    "Don't talk about colors since it's a grayscale image.\n",
    "If an image is just a black or blank screen, just say 'black' or 'blank'.\n",
    "Changes between frames are considered fast. \n",
    "Start directly with:\n",
    "{Frame number}: {Contextual description}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2=\"\"\"Here's a series of images spaced one second apart.\n",
    "With the eye of an expert biologist, mathematician, computer scientist, physicist, chemist, naturalist, historical and contemporary art, associate a lexical field at the same time precise, qualitative and quantitative, describing at high and low level, the following process and intricate patterns.\n",
    "Don't just say 'complex' or 'detailed', be more precise by using a tailored vocabulary to describe spatial and temporal patterns (even from one frame to the other), and making analogies with real-world objects or phenomena.\n",
    "Don't talk about colors since it's a grayscale image.\n",
    "If an image is just a black or blank screen, just say 'black' or 'blank'.\n",
    "Changes between frames are considered fast. \n",
    "Start directly with:\n",
    "Frame_{number}: {Detailed contextual lexical field}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_MESSAGES = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            p2\n",
    "           ,\n",
    "            *map(lambda x: {\"image\": x, \"resize\": 768}, base64Frames[500::500]\n",
    "                 ),\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "params = {\n",
    "    \"model\": \"gpt-4o\",\n",
    "    \"messages\": PROMPT_MESSAGES,\n",
    "    \"max_tokens\": 1000,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame_1: The pattern is centrally localized, resembling a quadrilateral geometric shape with rounded edges, similar to a four-lobed star or clover, with blurred boundaries suggesting diffusion processes, possibly indicative of biological cell division or crystallographic symmetry initiation.\n",
      "\n",
      "Frame_2: The previous structure has bifurcated into a more intricate configuration, showing a repetition of smaller clover-like shapes around a central void, reminiscent of fractal-like propagation or cellular automata growth dynamics, emphasizing geometric replication.\n",
      "\n",
      "Frame_3: Increased complexity is observed as the smaller clover-like shapes multiply and arrange in a square lattice configuration, forming an array that suggests a higher-order symbiotic pattern or lattice formation commonly seen in crystal growth or molecular aggregation.\n",
      "\n",
      "Frame_4: The structure further develops showing a central circular pattern with radial extensions forming a network of interconnected nodes, resembling a cellular matrix undergoing morphogenesis or a reaction-diffusion system indicative of Turing patterns in chemical reactions.\n",
      "\n",
      "Frame_5: There is a continued densification and expansion of the radial extensions, creating a denser and more interconnected mesh, akin to neural network development or the branching patterns seen in biological tissue growth and vascularization.\n",
      "\n",
      "Frame_6: The pattern demonstrates continuous radial expansion and increased nodal density, forming a highly interconnected, almost isotropic network, indicative of advanced states of diffusion-limited aggregation or dendritic solidification patterns.\n",
      "\n",
      "Frame_7: The structure's radial symmetry becomes more prominent, with extended nodal branches forming intricate loops and intersections, reminiscent of complex biological neural networks or advanced stages of crystal dendrite growth showing non-linear development symmetry.\n",
      "\n",
      "Frame_8: The complexity intensifies, showcasing a fractal-like, self-similar pattern extending towards the edges, suggesting nonlinear dynamical systems or percolation models in physics, where local interactions create emergent global patterns.\n",
      "\n",
      "Frame_9: The pattern approaches an isotropic state with intricate and intertwined pathways forming almost continuous regions, reminiscent of highly developed organic structures, such as reticulated networks in biological tissue or mature diffusive crystal growth, emphasizing emergent complexity and self-organization on a microscale.\n"
     ]
    }
   ],
   "source": [
    "result = client.chat.completions.create(**params)\n",
    "print(result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we embed the text to a vector\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "embedding = get_embedding(result.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adtool",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
